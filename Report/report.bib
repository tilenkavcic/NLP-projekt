

@inproceedings{Vintar2019ModellingSK,
  title={Modelling Specialized Knowledge With Conceptual Frames: The TermFrame Approach to a Structured Visual Domain Representation},
  author={Špela Vintar and Amanda Saksida and Katarina Vrtovec and Uroš Stepišnik},
  year={2019}
}

@misc{vpodpecanGithub,
  author = {Vid Podpečan},
  title = {webanno2csv},
  year = {2021},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://ghttps://github.com/vpodpecan/webanno2csv}},
  commit = {b1188988a67a29324feca2984c3212c3b045df90}
}
@article{Atzori2020,
  doi = {10.3390/info11050268},
  url = {https://doi.org/10.3390/info11050268},
  year = {2020},
  month = may,
  publisher = {{MDPI} {AG}},
  volume = {11},
  number = {5},
  pages = {268},
  author = {Maurizio Atzori and Simone Balloccu},
  title = {Fully-Unsupervised Embeddings-Based Hypernym Discovery},
  journal = {Information}
}

@article-journal{zhijiang_nodate,
    title = {Attention Guided Graph Convolutional Networks for Relation Extraction},
    author = {Guo, Zhijiang and Zhang, Yan and Lu, Wei},    
    doi = {10.18653/v1/p19-1024},
    url = {10.18653/v1/p19-1024},
    year = {2022},
    month = {03},

    urldate = {2022-3-18},
}

@article-journal{sunil_kumar_nodate,
    title = {Inter-sentence Relation Extraction with Document-level Graph Convolutional Neural Network},
    author = {Sahu, Sunil Kumar and Christopoulou, Fenia and Miwa, Makoto and Ananiadou, Sophia},    
    doi = {10.18653/v1/p19-1423},
    url = {10.18653/v1/p19-1423},
    year = {2022},
    month = {03},

    urldate = {2022-3-18},
}

@inproceedings{hearst-1992-automatic,
    title = "Automatic Acquisition of Hyponyms from Large Text Corpora",
    author = "Hearst, Marti A.",
    booktitle = "{COLING} 1992 Volume 2: The 14th {I}nternational {C}onference on {C}omputational {L}inguistics",
    year = "1992",
    url = "https://aclanthology.org/C92-2082",
}

@article{DBLP:journals/corr/abs-1806-03191,
  author    = {Stephen Roller and
               Douwe Kiela and
               Maximilian Nickel},
  title     = {Hearst Patterns Revisited: Automatic Hypernym Detection from Large
               Text Corpora},
  journal   = {CoRR},
  volume    = {abs/1806.03191},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.03191},
  eprinttype = {arXiv},
  eprint    = {1806.03191},
  timestamp = {Mon, 13 Aug 2018 16:48:51 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1806-03191.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
        
@inproceedings{bordea-etal-2016-semeval,
    title = "{S}em{E}val-2016 Task 13: Taxonomy Extraction Evaluation ({TE}x{E}val-2)",
    author = "Bordea, Georgeta  and
      Lefever, Els  and
      Buitelaar, Paul",
    booktitle = "Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016)",
    month = jun,
    year = "2016",
    address = "San Diego, California",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S16-1168",
    doi = "10.18653/v1/S16-1168",
    pages = "1081--1091",
}

@inproceedings{camacho-collados-etal-2018-semeval,
    title = "{S}em{E}val-2018 Task 9: Hypernym Discovery",
    author = "Camacho-Collados, Jose  and
      Delli Bovi, Claudio  and
      Espinosa-Anke, Luis  and
      Oramas, Sergio  and
      Pasini, Tommaso  and
      Santus, Enrico  and
      Shwartz, Vered  and
      Navigli, Roberto  and
      Saggion, Horacio",
    booktitle = "Proceedings of The 12th International Workshop on Semantic Evaluation",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S18-1115",
    doi = "10.18653/v1/S18-1115",
    pages = "712--724",
    abstract = "This paper describes the SemEval 2018 Shared Task on Hypernym Discovery. We put forward this task as a complementary benchmark for modeling hypernymy, a problem which has traditionally been cast as a binary classification task, taking a pair of candidate words as input. Instead, our reformulated task is defined as follows: given an input term, retrieve (or discover) its suitable hypernyms from a target corpus. We proposed five different subtasks covering three languages (English, Spanish, and Italian), and two specific domains of knowledge in English (Medical and Music). Participants were allowed to compete in any or all of the subtasks. Overall, a total of 11 teams participated, with a total of 39 different systems submitted through all subtasks. Data, results and further information about the task can be found at \url{https://competitions.codalab.org/competitions/17119}.",
}

@article{BERT:DBLP:journals/corr/abs-1810-04805,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  journal   = {CoRR},
  volume    = {abs/1810.04805},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.04805},
  eprinttype = {arXiv},
  eprint    = {1810.04805},
  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{distiledBert:DBLP:journals/corr/abs-1910-01108,
  author    = {Victor Sanh and
               Lysandre Debut and
               Julien Chaumond and
               Thomas Wolf},
  title     = {DistilBERT, a distilled version of {BERT:} smaller, faster, cheaper
               and lighter},
  journal   = {CoRR},
  volume    = {abs/1910.01108},
  year      = {2019},
  url       = {http://arxiv.org/abs/1910.01108},
  eprinttype = {arXiv},
  eprint    = {1910.01108},
  timestamp = {Tue, 02 Jun 2020 12:48:59 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1910-01108.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{roberta:DBLP:journals/corr/abs-1907-11692,
  author    = {Yinhan Liu and
               Myle Ott and
               Naman Goyal and
               Jingfei Du and
               Mandar Joshi and
               Danqi Chen and
               Omer Levy and
               Mike Lewis and
               Luke Zettlemoyer and
               Veselin Stoyanov},
  title     = {RoBERTa: {A} Robustly Optimized {BERT} Pretraining Approach},
  journal   = {CoRR},
  volume    = {abs/1907.11692},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.11692},
  eprinttype = {arXiv},
  eprint    = {1907.11692},
  timestamp = {Thu, 01 Aug 2019 08:59:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-11692.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{wei2019novel,
  title={A novel cascade binary tagging framework for relational triple extraction},
  author={Wei, Zhepei and Su, Jianlin and Wang, Yue and Tian, Yuan and Chang, Yi},
  journal={arXiv preprint arXiv:1909.03227},
  year={2019}
}

@inproceedings{hendrickx-etal-2010-semeval,
    title = "{S}em{E}val-2010 Task 8: Multi-Way Classification of Semantic Relations between Pairs of Nominals",
    author = "Hendrickx, Iris  and
      Kim, Su Nam  and
      Kozareva, Zornitsa  and
      Nakov, Preslav  and
      {\'O} S{\'e}aghdha, Diarmuid  and
      Pad{\'o}, Sebastian  and
      Pennacchiotti, Marco  and
      Romano, Lorenza  and
      Szpakowicz, Stan",
    booktitle = "Proceedings of the 5th International Workshop on Semantic Evaluation",
    month = jul,
    year = "2010",
    address = "Uppsala, Sweden",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S10-1006",
    pages = "33--38",
}
@article{ZHAO2021106888,
title = {Representation iterative fusion based on heterogeneous graph neural network for joint entity and relation extraction},
journal = {Knowledge-Based Systems},
volume = {219},
pages = {106888},
year = {2021},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.106888},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121001519},
author = {Kang Zhao and Hua Xu and Yue Cheng and Xiaoteng Li and Kai Gao},
keywords = {Relation extraction, Heterogeneous graph neural networks, Representation learning, Information extraction},
abstract = {Joint entity and relation extraction is an essential task in information extraction, which aims to extract all relational triples from unstructured text. However, few existing works consider possible relations information between entities before extracting them, which may lead to the fact that most of the extracted entities cannot constitute valid triples. In this paper, we propose a representation iterative fusion based on heterogeneous graph neural networks for relation extraction (RIFRE). We model relations and words as nodes on the graph and fuse the two types of semantic nodes by the message passing mechanism iteratively to obtain nodes representation that is more suitable for relation extraction tasks. The model performs relation extraction after nodes representation is updated. We evaluate RIFRE on two public relation extraction datasets: NYT and WebNLG. The results show that RIFRE can effectively extract triples and achieve state-of-the-art performance.11The code will be available at https://github.com/zhao9797/RIFRE. Moreover, RIFRE is also suitable for the relation classification task, and significantly outperforms the previous methods on SemEval 2010 Task 8 datasets.}
}
@article{cohen2020relation,
  title={Relation Classification as Two-way Span-Prediction},
  author={Cohen, Amir DN and Rosenman, Shachar and Goldberg, Yoav},
  journal={arXiv preprint arXiv:2010.04829},
  year={2020}
}

@inproceedings{qi2020stanza,
 author = {Qi, Peng and Zhang, Yuhao and Zhang, Yuhui and Bolton, Jason and Manning, Christopher D.},
 booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
 title = {Stanza: A {Python} Natural Language Processing Toolkit for Many Human Languages},
 url = {https://nlp.stanford.edu/pubs/qi2020stanza.pdf},
 year = {2020}
}

@inproceedings{pennington2014glove,
  author = {Jeffrey Pennington and Richard Socher and Christopher D. Manning},
  booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
  title = {GloVe: Global Vectors for Word Representation},
  year = {2014},
  pages = {1532--1543},
  url = {http://www.aclweb.org/anthology/D14-1162},
}

@article{sandhaus2008new,
  title={The new york times annotated corpus},
  author={Sandhaus, Evan},
  journal={Linguistic Data Consortium, Philadelphia},
  volume={6},
  number={12},
  pages={e26752},
  year={2008}
}

@Inproceedings{ulcar-robnik2020finest,
author = "Ulčar, M. and Robnik-Šikonja, M.",
year = 2020,
title = "{FinEst BERT} and {CroSloEngual BERT}: less is more in multilingual models",
editor = "Sojka, P and Kopeček, I and Pala, K and Horák, A",
booktitle = "Text, Speech, and Dialogue {TSD 2020}",
series = "Lecture Notes in Computer Science",
volume = 12284,
publisher = "Springer",
url = "https://doi.org/10.1007/978-3-030-58323-1_11",
}

