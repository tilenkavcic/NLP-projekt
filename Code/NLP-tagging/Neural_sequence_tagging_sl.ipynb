{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPc-wcQx4C2d",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# BERT for sequence labelling tasks (PyTorch example)\n",
    "<sup>This notebook is a part of Natural Language Processing class at the University of Ljubljana, Faculty for computer and information science. Please contact [slavko.zitnik@fri.uni-lj.si](mailto:slavko.zitnik@fri.uni-lj.si) for any comments.</sub>\n",
    "\n",
    "We will use a [Kaggle dataset](https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus) which is based on Groningen Meaning Bank dataset for named entity recognition.\n",
    "\n",
    "The model example was inspired and parts of code are taken from [Tobias Sterbak's blog post](https://www.depends-on-the-definition.com/named-entity-recognition-with-bert/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SeV0PHLm4LtC",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b24e491c-23f1-46cb-b448-4876855331d1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZEwTHhlj4VEz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(\"/content/drive/MyDrive/colab/Final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wc10rXj54fZM",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ffce6b75-1466-4984-fed1-a0d1d637763b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
      "\u001B[K     |████████████████████████████████| 4.2 MB 11.9 MB/s \n",
      "\u001B[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001B[K     |████████████████████████████████| 6.6 MB 39.3 MB/s \n",
      "\u001B[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001B[K     |████████████████████████████████| 596 kB 32.8 MB/s \n",
      "\u001B[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
      "\u001B[K     |████████████████████████████████| 84 kB 2.8 MB/s \n",
      "\u001B[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n",
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001B[K     |████████████████████████████████| 43 kB 1.4 MB/s \n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=2f94407e2a3705e2318bb594893998a215db58f39b4653b987841d62fbd157a4\n",
      "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q0tyTro64C2g",
    "outputId": "98893d95-c8d6-4005-fe88-946803194a64",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Transformers version: 4.19.2\n",
      "PyTorch version: 1.11.0+cu113\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import transformers\n",
    "from transformers import BertForTokenClassification, AdamW\n",
    "\n",
    "from seqeval.metrics import accuracy_score\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import f1_score\n",
    "import json\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OyFSAI6D5Jty",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_data(data, test=False):\n",
    "    dat = {\"Sentence #\": [], \"Word\": [], \"POS\": [], \"Tag\": []}\n",
    "    picked = ['GENUS', 'HAS_FORM', 'HAS_LOCATION', 'HAS_CAUSE', 'COMPOSITION_MEDIUM', 'HAS_SIZE', 'HAS_FUNCTION','GENUS_rev', 'HAS_FORM_rev', 'HAS_LOCATION_rev', 'HAS_CAUSE_rev', 'COMPOSITION_MEDIUM_rev', 'HAS_SIZE_rev', 'HAS_FUNCTION_rev']\n",
    "    # picked = ['GENUS']\n",
    "\n",
    "    for i, obj in enumerate(data):\n",
    "        # if obj[\"relation\"] not in picked:\n",
    "        #     continue\n",
    "\n",
    "        dat[\"Sentence #\"].append(\"Sentence: \" + str(i+1))\n",
    "        dat[\"Word\"] = dat[\"Word\"] + obj[\"token\"]\n",
    "        dat[\"POS\"] = dat[\"POS\"] + obj[\"stanford_pos\"]\n",
    "        dat[\"Sentence #\"] = dat[\"Sentence #\"] + [\"\"] * (len(obj[\"token\"]) - 1)\n",
    "\n",
    "        tag = [\"O\"] * len(obj[\"token\"])\n",
    "\n",
    "        for i, relation in enumerate(obj[\"relation\"]):\n",
    "            if relation in picked:\n",
    "                start = obj[\"subj_start\"][i]\n",
    "                end = obj[\"subj_end\"][i]\n",
    "                tag[start] = \"B-\" + relation\n",
    "                for i in range(start+1, end + 1):\n",
    "                    tag[i] = \"I-\" + relation\n",
    "\n",
    "        tag[obj[\"obj_start\"]] = \"B-DEFINIENDUM\"\n",
    "        for i in range(obj[\"obj_start\"]+1, obj[\"obj_end\"] + 1):\n",
    "            tag[i] = \"I-DEFINIENDUM\"\n",
    "\n",
    "        dat[\"Tag\"] = dat[\"Tag\"] + tag\n",
    "        if len(obj[\"token\"]) != len(obj[\"stanford_pos\"]):\n",
    "            print(\"FAK\")\n",
    "    return dat\n",
    "\n",
    "\n",
    "f = open(\"/content/drive/MyDrive/colab/Final/sl/karst_slo_tagger_train.json\")\n",
    "data_train = json.load(f)\n",
    "f.close()\n",
    "df_train = pd.DataFrame(convert_data(data_train))\n",
    "df_train.to_csv(\"./karst_train_data_loc.csv\", na_rep=\"\", index=False)\n",
    "\n",
    "f = open(\"/content/drive/MyDrive/colab/Final/sl/karst_slo_tagger_test.json\")\n",
    "data_test = json.load(f)\n",
    "f.close()\n",
    "df_test = pd.DataFrame(convert_data(data_test, test=True))\n",
    "df_test.to_csv(\"./karst_test_data_loc.csv\", na_rep=\"\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8m85DL0Kg-iO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_data(data, test=False):\n",
    "    dat = {\"Sentence #\": [], \"Word\": [], \"POS\": [], \"Tag\": []}\n",
    "    picked = ['GENUS', 'HAS_FORM', 'HAS_LOCATION', 'HAS_CAUSE', 'COMPOSITION_MEDIUM', 'HAS_SIZE', 'HAS_FUNCTION','GENUS_rev', 'HAS_FORM_rev', 'HAS_LOCATION_rev', 'HAS_CAUSE_rev', 'COMPOSITION_MEDIUM_rev', 'HAS_SIZE_rev', 'HAS_FUNCTION_rev']\n",
    "    # picked = ['HAS_FUNCTION']\n",
    "\n",
    "    for i, obj in enumerate(data):\n",
    "        # if obj[\"relation\"] not in picked:\n",
    "        #     continue\n",
    "\n",
    "        dat[\"Sentence #\"].append(\"Sentence: \" + str(i+1))\n",
    "        dat[\"Word\"] = dat[\"Word\"] + obj[\"token\"]\n",
    "        dat[\"POS\"] = dat[\"POS\"] + obj[\"stanford_pos\"]\n",
    "        dat[\"Sentence #\"] = dat[\"Sentence #\"] + [\"\"] * (len(obj[\"token\"]) - 1)\n",
    "\n",
    "        tag = [\"O\"] * len(obj[\"token\"])\n",
    "\n",
    "        for i, relation in enumerate(obj[\"relation\"]):\n",
    "            if relation in picked:\n",
    "                relation = \"SUBJECT\"\n",
    "                start = obj[\"subj_start\"][i]\n",
    "                end = obj[\"subj_end\"][i]\n",
    "                tag[start] = \"B-\" + relation\n",
    "                for i in range(start+1, end + 1):\n",
    "                    tag[i] = \"I-\" + relation\n",
    "\n",
    "        tag[obj[\"obj_start\"]] = \"B-DEFINIENDUM\"\n",
    "        for i in range(obj[\"obj_start\"]+1, obj[\"obj_end\"] + 1):\n",
    "            tag[i] = \"I-DEFINIENDUM\"\n",
    "\n",
    "        dat[\"Tag\"] = dat[\"Tag\"] + tag\n",
    "        if len(obj[\"token\"]) != len(obj[\"stanford_pos\"]):\n",
    "            print(\"FAK\")\n",
    "    return dat\n",
    "\n",
    "\n",
    "f = open(\"/content/drive/MyDrive/colab/Final/sl/karst_slo_tagger_train.json\")\n",
    "data_train = json.load(f)\n",
    "f.close()\n",
    "df_train = pd.DataFrame(convert_data(data_train))\n",
    "df_train.to_csv(\"./karst_train_data_objsub.csv\", na_rep=\"\", index=False)\n",
    "\n",
    "f = open(\"/content/drive/MyDrive/colab/Final/sl/karst_slo_tagger_test.json\")\n",
    "data_test = json.load(f)\n",
    "f.close()\n",
    "df_test = pd.DataFrame(convert_data(data_test, test=True))\n",
    "df_test.to_csv(\"./karst_test_data_objsub.csv\", na_rep=\"\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cRRbqjnw4C2i",
    "outputId": "659341b9-c4fb-4f8c-c3fb-318064c3fd10",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found GPU device: Tesla K80\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"Found GPU device: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l17oHqMX4C2i",
    "outputId": "e8f1fc59-e834-4cba-bb9e-75570388d6b3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(18937, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df_data = pd.read_csv(\"karst_train_data_objsub.csv\", encoding=\"utf8\").fillna(method=\"ffill\")\n",
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P7bWelul4C2j",
    "outputId": "d32c4347-97f3-4adb-9ca5-b50e2b3b0463",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<bound method NDFrame.head of           Sentence #         Word     POS            Tag\n",
      "0        Sentence: 1  prenikajoča  Appfsn  B-DEFINIENDUM\n",
      "1        Sentence: 1         voda   Ncfsn  I-DEFINIENDUM\n",
      "2        Sentence: 1            ,       Z              O\n",
      "3        Sentence: 1  pronicajoča  Appfsn              O\n",
      "4        Sentence: 1         voda   Ncfsn              O\n",
      "...              ...          ...     ...            ...\n",
      "18932  Sentence: 747          ali      Cc      I-SUBJECT\n",
      "18933  Sentence: 747            v      Sa      I-SUBJECT\n",
      "18934  Sentence: 747        višjo  Agcfsa      I-SUBJECT\n",
      "18935  Sentence: 747      votlino   Ncfsa      I-SUBJECT\n",
      "18936  Sentence: 747            .       Z              O\n",
      "\n",
      "[18937 rows x 4 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df_data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "usothjpa9fZO",
    "outputId": "e44fda06-9e38-40e2-f017-4d06153692c9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1812, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df_data_test = pd.read_csv(\"karst_test_data_objsub.csv\", encoding=\"utf8\").fillna(method=\"ffill\")\n",
    "df_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ckLGSB_4C2j",
    "outputId": "eea2550e-a8ff-409b-c426-e7fcfa638330",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tags: B-DEFINIENDUM, I-DEFINIENDUM, O, B-SUBJECT, I-SUBJECT, PAD\n"
     ]
    }
   ],
   "source": [
    "tag_list = df_data.Tag.unique()\n",
    "tag_list = np.append(tag_list, \"PAD\")\n",
    "print(f\"Tags: {', '.join(map(str, tag_list))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "evDNZxRt8nyS",
    "outputId": "70d1aa3a-d10d-42c6-a240-9c589a48ebe9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((18937, 4), (1812, 4))"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "x_train = df_data\n",
    "x_test = df_data_test\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B9_UZ44D4C2l",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "agg_func = lambda s: [ [w,t] for w,t in zip(s[\"Word\"].values.tolist(),s[\"Tag\"].values.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZGT4TdK44C2l",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_train_grouped = x_train.groupby(\"Sentence #\").apply(agg_func)\n",
    "x_test_grouped = x_test.groupby(\"Sentence #\").apply(agg_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26ogyudA4C2m",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_train_sentences = [[s[0] for s in sent] for sent in x_train_grouped.values]\n",
    "x_test_sentences = [[s[0] for s in sent] for sent in x_test_grouped.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SzLdVptf4C2m",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_train_tags = [[t[1] for t in tag] for tag in x_train_grouped.values]\n",
    "x_test_tags = [[t[1] for t in tag] for tag in x_test_grouped.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qunT_IWB4C2m",
    "outputId": "51f8245f-f551-4640-ba3f-f6e751a265ec",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['prenikajoča',\n",
       " 'voda',\n",
       " ',',\n",
       " 'pronicajoča',\n",
       " 'voda',\n",
       " ':',\n",
       " 'Padavinska',\n",
       " 'voda',\n",
       " ',',\n",
       " 'ki',\n",
       " 'v',\n",
       " 'aeracijski',\n",
       " 'coni',\n",
       " 'počasi',\n",
       " 'premika',\n",
       " 'skozi',\n",
       " 'vodoprepustne',\n",
       " 'skalne',\n",
       " 'gmote',\n",
       " '.',\n",
       " 'Voda',\n",
       " ',',\n",
       " 'ki',\n",
       " 'kaplja',\n",
       " 'z',\n",
       " 'jamskega',\n",
       " 'stropa',\n",
       " ';',\n",
       " 'od',\n",
       " 'tod',\n",
       " 'jamarski',\n",
       " 'izraz',\n",
       " 'kapnica',\n",
       " '.',\n",
       " 'Združeno',\n",
       " 'v',\n",
       " 'potoček',\n",
       " 'jo',\n",
       " 'imenujemo',\n",
       " 'tudi',\n",
       " 'vodni',\n",
       " 'curek',\n",
       " ',',\n",
       " 'v',\n",
       " 'nasprotju',\n",
       " 'od',\n",
       " 'globinskih',\n",
       " 'žil',\n",
       " '.']"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "x_train_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k4xFcSS34C2n",
    "outputId": "c365c1b2-8fd9-41e2-f9f3-5ca76db32eac",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['B-DEFINIENDUM',\n",
       " 'I-DEFINIENDUM',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-SUBJECT',\n",
       " 'I-SUBJECT',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-SUBJECT',\n",
       " 'I-SUBJECT',\n",
       " 'I-SUBJECT',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "x_train_tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iBM1Ff-E4C2n",
    "outputId": "12229117-45a9-4d38-dcad-9b84c7b265cc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'B-DEFINIENDUM': 0,\n",
       " 'B-SUBJECT': 3,\n",
       " 'I-DEFINIENDUM': 1,\n",
       " 'I-SUBJECT': 4,\n",
       " 'O': 2,\n",
       " 'PAD': 5}"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "label2code = {label: i for i, label in enumerate(tag_list)}\n",
    "code2label = {v: k for k, v in label2code.items()}\n",
    "label2code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kLGXUmPu4C2n",
    "outputId": "b46083c0-6e50-4f8e-b4e3-e652637793a2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of labels: 6\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(label2code)\n",
    "print(f\"Number of labels: {num_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kNGV8IUE4C2o",
    "outputId": "48d42a80-4d94-4047-a97f-c66e0bd397c5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GPU device: Tesla K80\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qSZ4_Wnw4C2o",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "aaf97f427e26474187d4b53810ff3a45",
      "3c13b89f527840fcbf579fa4e73b90ee",
      "be030ac51b3b4607837e814744547fce",
      "4951416c946a4a9eb29afb39a5c6bd04",
      "898b30bf2d0d4a1bbeb08ef5551a5a55",
      "52b63a5b15a04c69ba62e04e20ec0c96",
      "796349ba4ecd405ea86da703921c8aae",
      "373202bd2d6d4f17b1d3f9e10948e543",
      "553caad2335f49a38f6fa4926b8903cc",
      "2e84d2bfd7ef40c19a4119873529ee98",
      "df0270c256e440c0813eb4b00faffb5d",
      "b03064e8ada549569d4fb615d0c0a474",
      "7b089464b67c4020a1c06506e010fcda",
      "4e9af5e9147241dd9f0930d6d2d02618",
      "62388b93157b44259c41ae4cbeadd2c2",
      "a5d94bbad5534a04af9e0a13f261519d",
      "9e1d57272866498281f109fb0cdd9b9c",
      "c3b1e27e478c4f34bd3a7bacbf0687e8",
      "5bb8d135ac7c4c99aaf2fa746035a86a",
      "b39e823fa53d43cd8be0f32a4aba85cd",
      "f66a1404f4604834af6ff39eccfdf0d7",
      "bdc2fbb2aaf7489297d35631a0635b39",
      "cc5267d75c794e4ba1b1e34d931ca0d3",
      "4542410b022a477a8890b16ff10ad948",
      "dd327fdbab954d9d872a1b4040b09471",
      "81800401bf204d38bea4fa4ccce8e359",
      "36370355038c4798b90180316f6ff890",
      "fdfd041b59bc44468325ef8914288d59",
      "0a79601e24284345b128219e176e9815",
      "6b1d45d69f8e4c9db1c8e87ee53f90a0",
      "4a2f878c782f4395abfb081857c247ad",
      "1d282d17afbc4adc8937abd338793690",
      "479b5d0a41134e9483e1a01fecc5f081"
     ]
    },
    "outputId": "a0d95cfe-01a1-4a86-a19b-5bb6546f1cb3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading:   0%|          | 0.00/321k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aaf97f427e26474187d4b53810ff3a45"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading:   0%|          | 0.00/46.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b03064e8ada549569d4fb615d0c0a474"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cc5267d75c794e4ba1b1e34d931ca0d3"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('EMBEDDIA/crosloengual-bert', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DpGcPNl4C2o",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_input(sentences,tags):\n",
    "    input_id_list = []\n",
    "    attention_mask_list = []\n",
    "    label_id_list = []\n",
    "    \n",
    "    for x,y in tqdm(zip(sentences,tags),total=len(tags)):\n",
    "        tokens = []\n",
    "        label_ids = []\n",
    "        \n",
    "        for word, label in zip(x, y):\n",
    "            word_tokens = tokenizer.tokenize(word)\n",
    "            tokens.extend(word_tokens)\n",
    "            # Use the real label id for the first token of the word, and padding ids for the remaining tokens\n",
    "            label_ids.extend([label2code[label]] * len(word_tokens))\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        input_id_list.append(input_ids)\n",
    "        label_id_list.append(label_ids)\n",
    "\n",
    "    input_id_list = pad_sequences(input_id_list,\n",
    "                          maxlen=MAX_LENGTH, dtype=\"long\", value=0.0,\n",
    "                          truncating=\"post\", padding=\"post\")\n",
    "    label_id_list = pad_sequences(label_id_list,\n",
    "                     maxlen=MAX_LENGTH, value=label2code[\"PAD\"], padding=\"post\",\n",
    "                     dtype=\"long\", truncating=\"post\")\n",
    "    attention_mask_list = [[float(i != 0.0) for i in ii] for ii in input_id_list]\n",
    "\n",
    "    return input_id_list, attention_mask_list, label_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hdgXHC4x4C2o",
    "outputId": "dbb7e5ca-b55c-4865-9b62-09eabc9489b5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 747/747 [00:02<00:00, 249.96it/s]\n",
      "100%|██████████| 97/97 [00:00<00:00, 337.57it/s]\n"
     ]
    }
   ],
   "source": [
    "input_ids_train, attention_masks_train, label_ids_train = convert_to_input(x_train_sentences, x_train_tags)\n",
    "input_ids_test, attention_masks_test, label_ids_test = convert_to_input(x_test_sentences, x_test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2XUcPl1V4C2p",
    "outputId": "116a4ab0-67b6-4b98-9b2c-878f1f048fd7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((747, 128), (747, 128), (747, 128))"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "np.shape(input_ids_train), np.shape(attention_masks_train), np.shape(label_ids_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dA7c3QAK4C2p",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# np.shape(input_ids_val), np.shape(attention_masks_val), np.shape(label_ids_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "85zN3GX44C2p",
    "outputId": "80a103ad-54a9-4880-e75d-41e34b1b02ee",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((97, 128), (97, 128), (97, 128))"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "np.shape(input_ids_test), np.shape(attention_masks_test), np.shape(label_ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-BvAA7SJ4C2p",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(input_ids_train)\n",
    "train_tags = torch.tensor(label_ids_train)\n",
    "train_masks = torch.tensor(attention_masks_train)\n",
    "\n",
    "# val_inputs = torch.tensor(input_ids_val)\n",
    "# val_tags = torch.tensor(label_ids_val)\n",
    "# val_masks = torch.tensor(attention_masks_val)\n",
    "\n",
    "test_inputs = torch.tensor(input_ids_test)\n",
    "test_tags = torch.tensor(label_ids_test)\n",
    "test_masks = torch.tensor(attention_masks_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZFHwtgU4C2p",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_inputs, train_masks, train_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "# valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "# valid_sampler = SequentialSampler(valid_data)\n",
    "# valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_tags)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "45fe6b92b71e49abba45fc9e483aefdc",
      "967a5f2400ba459eab80fe438ab6583e",
      "7850bf86bd634637bbb44ec2bc3b9741",
      "cc60d68eb8744ff19a7d97c8cdb220f1",
      "cf2a8ff702fe467ba7a4a51429981905",
      "3217ed8bd00a4e0f9dce9434692748a5",
      "f07cdc882ce34524b8932b0cfad7fb03",
      "97dd9aca649045378045ce48ad48f78a",
      "b7526b7addf64348aa0f27a98d4e1940",
      "a711a4ec7e9b44dca62d852be6390cbb",
      "0b86243a44144eab838db4eac13b6800"
     ]
    },
    "id": "oR2fQGy74C2p",
    "outputId": "441b4acb-28f7-4197-c169-9a23f593a927",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading:   0%|          | 0.00/476M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45fe6b92b71e49abba45fc9e483aefdc"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at EMBEDDIA/crosloengual-bert were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at EMBEDDIA/crosloengual-bert and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\n",
    "    \"EMBEDDIA/crosloengual-bert\",\n",
    "    num_labels=len(label2code),\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qox-FHGC4C2q",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGkI4YBc4C2q",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In the part below we must pass all the parameters that can be finetuned to the optimizer. If we set *FULL_FINETUNING* to False, we will finetune just the model head. Otherwise the whole model weights will be updated. \n",
    "\n",
    "Gamma and beta are parameters by the *BERTLayerNorm* and should not be regularized. We can include also all parameters to the regularization and will achieve similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gEJ7uK7R4C2q",
    "outputId": "075b897c-7f65-48ca-ca0c-002ec764675d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "FULL_FINETUNING = True\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.classifier.named_parameters())\n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "\n",
    "optimizer = AdamW(\n",
    "    optimizer_grouped_parameters,\n",
    "    lr=3e-5,\n",
    "    eps=1e-8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NYK_91G34C2q",
    "outputId": "36edb2d6-4ecc-4bf3-dd78-e10d3b300db2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The model has 123548934 trainable parameters\n",
      "The classifier-only model has 4614 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(f\"The model has {params} trainable parameters\")\n",
    "\n",
    "model_classifier_parameters = filter(lambda p: p.requires_grad, model.classifier.parameters())\n",
    "params_classifier = sum([np.prod(p.size()) for p in model_classifier_parameters])\n",
    "print(f\"The classifier-only model has {params_classifier} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyYrTLfQ4C2q",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 20\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27pQD8RJ4C2q",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KavYbGyU4C2r",
    "outputId": "27808977-de95-420c-9248-a1fa1993ffba",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "24it [00:14,  1.65it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average train loss: 0.5654871910810471\n",
      "Epoch 2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "24it [00:14,  1.64it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average train loss: 0.24584624357521534\n",
      "Epoch 3\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "24it [00:14,  1.62it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average train loss: 0.18612874299287796\n",
      "Epoch 4\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "24it [00:15,  1.59it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average train loss: 0.15213345053295294\n",
      "Epoch 5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "24it [00:15,  1.56it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average train loss: 0.12872941512614489\n",
      "Epoch 6\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "24it [00:16,  1.49it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average train loss: 0.10060382665445407\n",
      "Epoch 7\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "24it [00:15,  1.54it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average train loss: 0.08227872553591926\n",
      "Epoch 8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "24it [00:15,  1.52it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average train loss: 0.07074639325340588\n",
      "Epoch 9\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "24it [00:16,  1.49it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average train loss: 0.05808649848525723\n",
      "Epoch 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "24it [00:16,  1.46it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average train loss: 0.052795977952579655\n",
      "Epoch 11\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "24it [00:16,  1.44it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average train loss: 0.04649575691049298\n",
      "Epoch 12\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "24it [00:16,  1.42it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average train loss: 0.04333012279433509\n",
      "Epoch 13\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "24it [00:16,  1.43it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average train loss: 0.03929912896516422\n",
      "Epoch 14\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "24it [00:16,  1.42it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average train loss: 0.03670693258754909\n",
      "Epoch 15\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "24it [00:16,  1.43it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average train loss: 0.033254939674710236\n",
      "Epoch 16\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "24it [00:17,  1.40it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average train loss: 0.03020313537369172\n",
      "Epoch 17\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "24it [00:17,  1.39it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average train loss: 0.028654250937203567\n",
      "Epoch 18\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "24it [00:17,  1.41it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average train loss: 0.028086219254570704\n",
      "Epoch 19\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "24it [00:17,  1.40it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average train loss: 0.026446854307626683\n",
      "Epoch 20\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "24it [00:17,  1.39it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average train loss: 0.027228290447965264\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Store the average loss after each epoch so we can plot them.\n",
    "loss_values, test_loss_values = [], []\n",
    "\n",
    "for epoch_id in range(epochs):\n",
    "    print(f\"Epoch {epoch_id+1}\")\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    # Put the model into training mode.\n",
    "    model.train()\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Training loop\n",
    "    for step, batch in tqdm(enumerate(train_dataloader)):\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Always clear any previously calculated gradients before performing a backward pass.\n",
    "        model.zero_grad()\n",
    "        # forward pass\n",
    "        # This will return the loss (rather than the model output)\n",
    "        # because we have provided the `labels`.\n",
    "        outputs = model(b_input_ids, token_type_ids=None,\n",
    "                        attention_mask=b_input_mask, labels=b_labels)\n",
    "        # get the loss\n",
    "        loss = outputs[0]\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "        # track train loss\n",
    "        total_loss += loss.item()\n",
    "        # Clip the norm of the gradient\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(\"Average train loss: {}\".format(avg_train_loss))\n",
    "\n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nEaYh2lq4C2r",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model, 'karst_bert_all_subj_obj.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQXWjR_g4C2r",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Loading a model (see docs for different options)\n",
    "model = torch.load('karst_bert_all_subj_obj.pt', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NL5EGpIr4C2s",
    "outputId": "4dc63a82-3c50-4a45-db22-21e2d4d07d57",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pytorch is using: cuda\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 4/4 [00:37<00:00,  9.44s/it]\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Pytorch is using: {device}\")\n",
    "\n",
    "predictions , true_labels = [], []\n",
    "for batch in tqdm(test_dataloader):\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    b_input_ids.to(device)\n",
    "    b_input_mask.to(device)\n",
    "    b_labels.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, token_type_ids=None,\n",
    "                        attention_mask=b_input_mask, labels=b_labels)\n",
    "\n",
    "    logits = outputs[1].detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "    true_labels.extend(label_ids)\n",
    "\n",
    "results_predicted = [[code2label[p_i] for (p_i, l_i) in zip(p, l) if code2label[l_i] != \"PAD\"] \n",
    "                                      for p, l in zip(predictions, true_labels)]\n",
    "results_true = [[code2label[l_i] for l_i in l if code2label[l_i] != \"PAD\"] \n",
    "                                 for l in true_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Atrkmv1i4C2s",
    "outputId": "bab1719e-1208-4284-864e-8782775c3f48",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F1 score: 0.6057692307692308\n",
      "Accuracy score: 0.6919482386772107\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.00      0.00      0.00         0\n",
      " DEFINIENDUM       0.86      0.90      0.88       244\n",
      "     SUBJECT       0.42      0.44      0.43       365\n",
      "\n",
      "   micro avg       0.59      0.62      0.61       609\n",
      "   macro avg       0.42      0.44      0.43       609\n",
      "weighted avg       0.59      0.62      0.61       609\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(f\"F1 score: {f1_score(results_true, results_predicted)}\")\n",
    "print(f\"Accuracy score: {accuracy_score(results_true, results_predicted)}\")\n",
    "print(classification_report(results_true, results_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Au10ZC5rkeb4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# MAKE PREDICTION CSV\n",
    "import re\n",
    "def make_pred_db(sentences, tags):\n",
    "    dat = {\"Sentence #\": [], \"Word\": [], \"Tag_predicted\": []}\n",
    "    for i, sent in enumerate(sentences):\n",
    "        # tag = tags[i]\n",
    "\n",
    "        dat[\"Sentence #\"].append(\"Sentence: \" + str(i+1))\n",
    "\n",
    "        # dat[\"Word\"] = dat[\"Word\"] + sent\n",
    "        # dat[\"Tag_real\"] = dat[\"Tag_real\"] + tag\n",
    "\n",
    "        sentence_s = \" \".join(sent)\n",
    "        sentence_s = re.sub(r'\\s([?.!\"](?:\\s|$))', r'\\1', sentence_s)\n",
    "\n",
    "        tokenized_sentence = tokenizer.encode(sentence_s)\n",
    "        input_ids = torch.tensor([tokenized_sentence])\n",
    "        output = model(input_ids)\n",
    "        label_indices = np.argmax(output[0].to('cpu').detach().numpy(), axis=2)\n",
    "\n",
    "        tokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
    "        new_tokens, new_labels = [], []\n",
    "        for token, label_idx in zip(tokens, label_indices[0]):\n",
    "            if token.startswith(\"##\"):\n",
    "                new_tokens[-1] = new_tokens[-1] + token[2:]\n",
    "            else:\n",
    "                new_labels.append(code2label[label_idx])\n",
    "                new_tokens.append(token)\n",
    "        \n",
    "        for j, s in enumerate(new_tokens):\n",
    "            if s[0] == \"[\":\n",
    "                new_tokens.pop(j)\n",
    "                new_labels.pop(j)\n",
    "\n",
    "        dat[\"Sentence #\"] = dat[\"Sentence #\"] + [\"\"] * (len(new_tokens) - 1)\n",
    "        dat[\"Word\"] = dat[\"Word\"] + new_tokens\n",
    "        dat[\"Tag_predicted\"] = dat[\"Tag_predicted\"] + new_labels\n",
    "\n",
    "    return dat\n",
    "\n",
    "df = make_pred_db(x_test_sentences, x_test_tags)\n",
    "df = pd.DataFrame(df)\n",
    "df.to_csv(\"./karst_predicted_subj_obj.csv\", na_rep=\"\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# MAKE TXT\n",
    "import re\n",
    "\n",
    "def make_pred_db(sentences, tags):\n",
    "    res = \"\"\n",
    "    for i, sent in enumerate(sentences):\n",
    "        sentence_s = \" \".join(sent)\n",
    "        sentence_s = re.sub(r'\\s([?.!\"](?:\\s|$))', r'\\1', sentence_s)\n",
    "\n",
    "        tokenized_sentence = tokenizer.encode(sentence_s)\n",
    "        input_ids = torch.tensor([tokenized_sentence])\n",
    "        output = model(input_ids)\n",
    "        label_indices = np.argmax(output[0].to('cpu').detach().numpy(), axis=2)\n",
    "\n",
    "        tokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
    "\n",
    "        new_tokens, new_labels = [], []\n",
    "        for token, label_idx in zip(tokens, label_indices[0]):\n",
    "            if token.startswith(\"##\"):\n",
    "                new_tokens[-1] = new_tokens[-1] + token[2:]\n",
    "            else:\n",
    "                new_labels.append(code2label[label_idx])\n",
    "                new_tokens.append(token)\n",
    "        \n",
    "        for j, s in enumerate(new_tokens):\n",
    "            if s[0] == \"[\":\n",
    "                new_tokens.pop(j)\n",
    "                new_labels.pop(j)\n",
    "\n",
    "        tab = new_labels.copy()\n",
    "        tab_lab = new_tokens.copy()\n",
    "        for j, t in enumerate(tab):\n",
    "            if t != \"O\" and t != \"PAD\":\n",
    "                tab[j] = t[2:]\n",
    "            if t == \"PAD\":\n",
    "                tab[j] = \"O\"\n",
    "        subjStart = True\n",
    "        objStart = True\n",
    "        j = 0\n",
    "        indx_open = []\n",
    "        indx_close = []\n",
    "        while j < len(tab):\n",
    "            if (tab[j] == \"SUBJECT\" and j == 0) or (tab[j] == \"SUBJECT\" and tab[j-1] != \"SUBJECT\"):\n",
    "                tab.insert(j, \"<e1>\")\n",
    "                tab_lab.insert(j, \"<e1>\")\n",
    "                indx_open.append(j)\n",
    "                j += 1\n",
    "            if j != 0 and tab[j-1] == \"SUBJECT\" and tab[j] != \"SUBJECT\":\n",
    "                tab.insert(j, \"</e1>\")\n",
    "                tab_lab.insert(j, \"</e1>\")\n",
    "                indx_close.append(j)\n",
    "                j += 1\n",
    "\n",
    "            if (tab[j] == \"DEFINIENDUM\" and j == 0) or (tab[j] == \"DEFINIENDUM\" and tab[j-1] != \"DEFINIENDUM\"):\n",
    "                tab.insert(j, \"<e2>\")\n",
    "                tab_lab.insert(j, \"<e2>\")\n",
    "                indx_open.append(j)\n",
    "                j += 1\n",
    "            if j != 0 and tab[j-1] == \"DEFINIENDUM\" and tab[j] != \"DEFINIENDUM\":\n",
    "                tab.insert(j, \"</e2>\")\n",
    "                tab_lab.insert(j, \"</e2>\")\n",
    "                indx_close.append(j)\n",
    "                j += 1\n",
    "\n",
    "            j += 1\n",
    "\n",
    "        sentence = \"\"\n",
    "        for j, s in enumerate(tab_lab):\n",
    "            if j in indx_open:\n",
    "                sentence += s\n",
    "            elif j in indx_close:\n",
    "                sentence = sentence[:-1]\n",
    "                sentence += s\n",
    "                sentence += \" \"\n",
    "            else:\n",
    "                sentence += f\"{s} \"\n",
    "        \n",
    "        sentence = sentence[:-1]\n",
    "        sentence = re.sub(r'\\s([?.!\"](?:\\s|$))', r'\\1', sentence)\n",
    "\n",
    "        res +=f\"{i+1}\\t\\\"{sentence}\\\"\\n\\n\"\n",
    "\n",
    "\n",
    "    return res\n",
    "txt = make_pred_db(x_test_sentences, x_test_tags)\n",
    "\n",
    "with open('subj_obj_input.txt', 'w') as f:\n",
    "    f.write(txt)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oUXVsiuFRSwK",
    "outputId": "09ef5f26-e505-4a44-f5b7-353f1e32115b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<e1>Vsako obdobje otoplitve</e1> in s tem zmanjšanje obsega <e1>ledenikov</e1> imenujemo <e2>medledena doba</e2> ali <e2>interglacial</e2> .\n",
      "Takšnim meandrom pravimo tudi <e2>ujeti</e2> meandri in jih najdemo tudi v nekaterih drugih slovenskih pokrajinah .\n",
      "V leksikonu je <e2>spodmol</e2> definiran kot \" <e1>kratka votlina z visoko previsno steno na vhodu</e1> \" in kot \" <e1>zaradi delovanja valov izpodjeden previs na morski</e1> , <e1>jezerski obali</e1> \"\n",
      "V geologiji je <e2>zemeljski plaz</e2> definiran kot <e1>območje preperine , usedline ali kamnine</e1> , <e1>ki se je hitro ali počasi premaknila s prvotnega kraja in ima vidno spremenjeno površje</e1> .\n",
      "V najstarejši literaturi izraz <e2>spodmol</e2> pomeni <e1>majhno izravnavo na povešenih gorskih hrbtih</e1> in <e1>slemenih</e1> .\n",
      "<e1>Spodmole</e1> opišejo kot <e1>vodoravne vdolbine</e1> / <e1>zajede v obliki črke C v navpičnem prerezu</e1> , <e1>izdolbene na pobočjih in v skalnih stenah</e1> . skalnih\n",
      "Uporablja se pojem <e2>prebojna dolina</e2> , kar pa je samo slovenski izraz za antecedentno <e1>dolino</e1> , to je tisti <e1>del rečne doline</e1> , ki <e1>se</e1> je <e1>ob dviganju antiklinale vrezal prečno na antiklinalo</e1> .\n",
      "Izraz <e2>denudacija</e2> označuje <e1>razgaljanje površja</e1> oziroma <e1>ploskovno odstranjevanje preperelih snovi s površja zemlje z eksogenimi procesi</e1> . <e1>površja</e1> preperelih snovi ploskovno\n",
      "Z izrazom <e2>zemeljski plaz</e2> razumejo tako <e1>proces</e1> , to je \" <e1>premikanje kamnin ali zemlje po pobočju navzdol pod vplivom gravitacije</e1> . . . \" .\n",
      "Tovrstno izoblikovanost <e1>krasa</e1> , <e1>kjer se osamljeno dvigajo več deset ali sto metrov visoke vzpetine</e1> , imenujemo <e2>kopasti kras</e2> .\n",
      "<e1>Tip kraškega površja</e1> , kjer je prevladujoča oblika <e1>vrtače</e1> , imenujemo <e2>vrtačasti kras</e2> .\n",
      "<e2>Holocen</e2> predstavlja <e1>medledeno dobo</e1> , ki se je <e1>začela</e1> pred približno 11 . <e1>000</e1> leti s <e1>hitrim zviševanjem morske gladine</e1> .\n",
      "<e1>Te razmeroma zaprte kotanje z obsežnim</e1> , <e1>z vrtačami razčlenjenim dnom</e1> , imenujemo <e2>uvale</e2> .\n",
      "Ta proces oblikovanja rovov <e1>na kontaktnem krasu</e1> imenujemo <e2>parageneza</e2> . rovov\n",
      "Take <e1>jame</e1> imenujemo <e2>paragenetske jame</e2> , zaradi <e1>njihove lege v občasno zaliti coni</e1> pa jih lahko imenujemo tudi <e2>epifreatične jame</e2> .\n",
      "<e1>Nad kraškim izvirom</e1> se pojavlja <e1>strm</e1> konec <e1>doline</e1> , ki ga imenujemo <e2>zatrep</e2> .\n",
      "Oznaka <e2>okno</e2> se v geografiji uporablja za <e1>večjo odprtino</e1> , <e1>skozi katero</e1> se <e1>vidi ozadje</e1> .\n",
      "<e1>Sloj med najvišjim in najnižjim nivojem podzemne vode v krasu</e1> imenujemo <e2>epifreatična cona</e2> .\n",
      "Gladino <e1>vodnega telesa v freatični coni</e1> imenujemo <e1>nivo</e1> <e2>podzemne <e1>vode v krasu</e1> .\n",
      "Višina <e1>točke</e1> , ki jo imenujemo raven združevanja , je sorazmerna meri različnosti med skupinama .\n",
      "<e1>Enote površja</e1> , <e1>v</e1> katerih <e1>potekajo</e1> enaki ali podobni <e1>procesi</e1> , <e1>homogeni po vrsti</e1> in <e1>intenzivnosti</e1> , imenujemo <e2>morfogenetske <e1>enote</e1> .\n",
      "<e1>Zelo strmo pobočje z naklonom nad 55 ali 65</e1> imenujemo <e2>stena</e2> ali <e1>klif</e1> .\n",
      "Vse <e1>pojave premeščanja gradiva</e1> , ki <e1>nastanejo zaradi vpliva gravitacije</e1> in so <e1>pomemben dejavnik denudacije površja</e1> , imenujemo <e2>pobočni procesi</e2> .\n",
      "<e1>Spremembo</e1> Shannonove <e1>entropije</e1> imenujemo <e2>Kolmogorovova entropija</e2> in je enaka vsoti pozitivnih Lyapunovovih eksponentov .\n",
      "Samo - podobne <e1>geometrične objekte</e1> imenujemo tudi <e2>fraktali</e2> .\n",
      "<e1>Fraktalna dimenzija</e1> je tudi <e1>mera razgibanosti</e1> površja .\n",
      "S <e1>preperevanjem apnenca</e1> in <e1>dolomita</e1> nastane <e1>iz netopnih ostankov ilovica</e1> , ki jo skupaj s huminskimi <e1>snovmi</e1> imenujemo <e2>jerovica</e2> . netopnih\n",
      "<e2>Jerovica</e2> je <e1>povečini zmes kremenice</e1> , <e1>aluminijevih</e1> in železovih <e1>oksidov</e1> .\n",
      "<e1>Kronometrične</e1> in <e1>inkrementalne metode</e1> datiranja imenujemo tudi <e1>absolutne metode</e1> ali radiometrične <e1>metode</e1> .\n",
      "<e1>Sediment nastane s trenjem</e1> in ga imenujemo <e2>tektonska glina</e2> zaradi velikosti delcev .\n",
      "<e1>Vsako povečanje obsega poledenitve</e1> imenujemo <e2>ledena doba</e2> ali glacial .\n",
      "Ljudsko ime <e2>lašt</e2> izhaja iz območja Julijskih Alp in ponazarja specifično obliko <e1>škrapelj</e1> . Gre <e1>za večje skladovne police</e1> ali <e1>kamnite ploskve z velikimi ravnimi strukturnimi površinami</e1> in <e1>enakim strmcem</e1> .\n",
      "<e1>Preperevanje</e1> ali <e1>vodna erozija</e1> odnese / izpodje manj <e1>odporno kamnino</e1> , ostane pa bolj odporna <e1>kamnina</e1> , ki <e1>predstavlja streho spodmola</e1> .\n",
      "Pri izrazu <e2>pobočni procesi</e2> ime pove , da gre za procese , ki se dogajajo <e1>na pobočjih</e1> .\n",
      "<e2>Uvala</e2> je <e1>večja kraška globel skledaste oblike z neravnim dnom in sklenjenim višjim obodom</e1> . Praviloma <e1>je manjša od kraškega polja</e1> in <e1>večja od vrtače</e1> .\n",
      "Slovenska kraška terminologija navaja , da je <e2>vrtača</e2> : <e1>depresijska oblika okroglaste oblike</e1> , <e1>navadno globoka več metrov</e1> in <e1>je bolj široka kot globoka</e1> .\n",
      "<e2>Požiralnik</e2> je definiran kot <e1>špranja</e1> ali <e1>brezno v skalnem koritu</e1> , <e1>ki požira vodo</e1> , <e1>ponikev</e1> kot <e1>odprtina</e1> , <e1>v katero ponika voda</e1> in <e1>je večinoma prekrita z naplavino</e1> , ponor pa kot <e1>večja vodoravna odprtina v katero teče potok</e1> ali <e1>reka\n",
      "Slovenska kraška terminologija opredeli hum kot osamljen <e1>korozijsko - erozijsko - denudacijski ostanek višjega reliefa</e1> , <e1>zlasti na dnu kraškega polja</e1> .\n",
      "Ford in Williams opišeta <e2>hume</e2> kot eno izmed štirih tipov <e1>stolpičastega krasa</e1> , in sicer kot <e1>ostanke vzpetin</e1> , <e1>ki štrlijo iz izravnanega karbonatnega površja</e1> , <e1>ki ga prekriva aluvij</e1> . karbonatnega\n",
      "<e2>Kraška polja</e2> so največje in gospodarsko najpomembnejše <e1>kotanje v</e1> <e2>dinarskem <e1>krasu</e1> .\n",
      "<e2>Škavnice</e2> so <e1>skledaste vdolbine na vodoravni ali rahlo nagnjeni skalni podlagi</e1> .\n",
      "<e1>Žlebiči</e1> in <e1>žlebovi</e1> so <e1>žlebaste izjedenine s polkrožnim prečnim prerezom</e1> , <e1>ki se oblikujejo na ravnem kompaktnem skalnem površju</e1> in <e1>potekajo v smeri največjega naklona\n",
      "<e2>Erozijski jarki <e1>nastanejo s kanaliziranjem površinskega toka</e1> , predvsem <e1>tam</e1> , <e1>kjer so že reliefno ( naravno ) zasnovane linije odtoka</e1> , pa tudi <e1>ob</e1> raznih <e1>antropogenih oblikah</e1> ( <e1>npr</e1> . <e1>izkopih , njivskih brazdah , mejah parcel , poteh</e1> in <e1>cestah</e1> ) .\n",
      "<e2>Veter</e2> je <e1>gibanje zraka</e1> , ki <e1>nastane zaradi razlik v zračnem tlaku</e1> .\n",
      "<e1>Proces</e1> , <e1>v katerem se trdna kompaktna kamnina pod vplivom eksogenih dejavnikov razkraja v manjše in med seboj nepovezane delce</e1> , imenujemo <e2>preperevanje</e2> .\n",
      "<e2>Tlačna trdnost</e2> je <e1>odpornost proti tlačni obremenitvi</e1> , ki <e1>jo kamnina prenese , preden se zdrobi</e1> .\n",
      "Po prvi definiciji je <e2>spodmol <e1>prostor pod previsom v skalovju</e1> , po drugi pa <e1>kratka vodoravna jama pod previsno steno</e1> . kratka\n",
      "<e1>Večji</e1> ali manjši del <e1>kraškega polja</e1> je <e1>ravnica</e1> , <e1>običajno obdelana zemlja</e1> , <e1>ki je največkrat na naplavini ali debeli prsti</e1> .\n",
      "<e1>Odlaganje sige</e1> je <e1>proces</e1> , ki je ravno nasproten <e1>koroziji</e1> .\n",
      "<e2>Glaciologija</e2> je <e1>raziskava</e1> in preučevanje ledenikov , ledenih <e1>plošč</e1> , <e1>morskega ledu</e1> , <e1>sezonskega snega</e1> , zamrznjenih <e1>tal</e1> in vseh drugih naravnih <e1>pojavov</e1> , ki vključujejo led in njegove učinke na okolje .\n",
      "Podkategorija te znanosti je <e1>astroglaciologija</e1> , ki je <e1>nastala</e1> po <e1>odkritju vodnega ledu na Luni , Evropi</e1> , Marsu in Plutonu .\n",
      "<e2>Spodmol</e2> je definiran tudi kot <e1>previs na morski ,</e1> redkeje <e1>jezerski obali</e1> , ki <e1>ga ustvari erozijsko delovanje valov</e1> in kot <e1>kraška jama</e1> .\n",
      "<e1>Škraplje</e1> so ena izmed najbolj tipičnih <e1>površinskih kraških oblik</e1> , ki jih <e1>sestavljajo korozijsko razširjene razpoke</e1> ter <e1>vmesni bloki</e1> .\n",
      "<e2>Kopasti vrhovi</e2> so najpogostejši tip <e1>kraške vzpetine</e1> . Gre <e1>za višje predele kraškega površja</e1> , <e1>ki</e1> navadno <e1>ležijo med zaprtimi kraškimi kotanjami</e1> različnih <e1>dimenzij</e1> , kot so uvale , <e1>vrtače</e1> in druge manjše <e1>globeli</e1> .\n",
      "<e1>Kotliči so skalnate globeli okrogle</e1> , <e1>podolgovate ali oglate oblike s premerom in globino nekaj metrov ter strmimi do navpičnimi stenami</e1> .\n",
      "V gradbeništvu oziroma <e1>vodarstvu</e1> pojem <e2>težnostna erozija</e2> obsega pojave plazne , usadne in <e1>podorne</e1> erozije oziroma pojave , ki jih pogosto imenujemo skupaj kar <e2>zemeljski</e2> plazovi .\n",
      "Jame so pogosto opredeljene kot <e1>naravne podzemeljske votline</e1> , <e1>ki so prehodne za človeka</e1> .\n",
      "<e2>Vrtače <e1>so</e1> običajno <e1>krožne do polkrožne reliefne oblike</e1> , <e1>ki se razlikujejo v premeru od nekaj m do 1 km</e1> .\n",
      "<e1>Vdolbinice</e1> se <e1>pojavljajo kot majhne izjedenine v skalni podlagi</e1> .\n",
      "<e1>Odlaganje sige</e1> je <e1>proces</e1> , ki je ravno <e1>nasproten koroziji</e1> . Odlaganje\n",
      "<e2>Suho kraško polje</e2> je tisto <e1>kraško polje</e1> , ki je brez izvirov ali ponorov , zato ni stalnih ali občasnih vodotokov .\n",
      "Prisotne so tudi <e1>večje kraške oblike</e1> , kot so <e1>uvale</e1> in številne <e1>vrtače</e1> .\n",
      "<e2>Kemično preperevanje</e2> je <e1>razgrajevanje kamnine pod vplivom vode</e1> in <e1>v njej raztopljenih snovi</e1> .\n",
      "<e2>Kraška polja</e2> sodijo med največje <e1>kraške kotanje</e1> .\n",
      "<e2>Vrtača</e2> je <e1>manj ša oblika kraške globeli</e1> , <e1>ki je bolj široka kot globoka</e1> .\n",
      "<e2>Kraška polja</e2> so <e1>največje oblike kraških kotanj na krasu</e1> .\n",
      "<e1>Pojav</e1> prištevamo k <e1>skalnim podorom</e1> in ga v geografiji imenujemo <e2>kamniti zdrs</e2> .\n",
      "<e2>Erozijski jarki</e2> so <e1>fluvialna erozijska oblika</e1> , ki je <e1>na proučevanih območjih</e1> najpogostej ša <e1>na pobočjih kotanj</e1> .\n",
      "V literaturi je <e2>kontaktni kras</e2> največkrat definiran kot <e1>stik med nekarbonatnimi in karbonatnimi kamninami</e1> .\n",
      "<e2>Fluviokras</e2> tuja literatura opredeljuje kot <e1>površje na karbonatnih kamninah</e1> , <e1>kjer</e1> so prevladujoče <e1>oblike na</e1> površju doline , ki so jih <e1>oblikovale površinske reke</e1> .\n",
      "<e2>Fluviokraško površje</e2> je <e1>prehodna oblika kraškega reliefa</e1> , <e1>kjer prevladuje odnašanje materiala</e1> in <e1>se</e1> površje mestoma <e1>preoblikuje fluvialno</e1> .\n",
      "<e2>Erozijski jarki</e2> so tipična <e1>fluviokraška oblika</e1> , <e1>kjer se zaradi lokalne prevlade mehanskega odtoka materiala površje preoblikuje fluvialno</e1> .\n",
      "V literaturi so <e1>ponikve</e1> definirane kot <e1>vertikalni odtoki površinske vode v podzemlje</e1> , <e1>kjer je površje delno ali povsem prekrito z naplavino</e1> .\n",
      "<e2>Slepe <e1>doline</e1> so najbolj značilna <e1>oblika ponornega kontaktnega krasa</e1> .\n",
      "<e2>Paragenezo</e2> razumemo kot <e1>proces erodiranja</e1> in <e1>korodiranja jamskega stropa do gladine podzemne vode</e1> ter <e1>akumulacije alogenega materiala na dno rova</e1> .\n",
      "<e1>Tafon</e1> in <e1>niša</e1> ( spodmoli ) sta dve različni <e1>reliefni obliki</e1> , čeprav naj bi obe obliki <e1>nastali z votlinastim preperevanjem</e1> . Po drugi strani imamo avtorje , ki spodmole enačijo s tafoni .\n",
      "<e2>Geomorfologija</e2> je <e1>veda</e1> , ki <e1>razlaga odnose</e1> med <e1>geomorfnimi procesi</e1> in <e1>reliefnimi oblikami</e1> .\n",
      "<e1>Spodnji del plazu</e1> imenujemo <e2>čelo</e2> .\n",
      "<e2>Dinarski kras</e2> je kompletno razvit <e1>kras</e1> , katerega značilnost so <e1>velike</e1> kraške <e1>depresije</e1> ali z drugimi besedami kraška polja .\n",
      "<e2>Zoogena breča</e2> je značilna <e1>kamnina</e1> tega <e1>obdobja</e1> , ki <e1>je nastala predvsem iz ostankov favnističnega izvora</e1> .\n",
      "<e2>Jarkovna erozija</e2> je <e1>globinska erozija</e1> , pri kateri na primer z <e1>zdruèvanjem erozijskih žlebičev</e1> nastajajo <e1>več metrov globoko</e1> in <e1>več deset metrov dolgi</e1> erozijski <e1>jarki</e1> .\n",
      "<e2>Plazovitost</e2> je <e1>skladnost med usmerjenostjo pobočij</e1> in <e1>vpadom kamninskih plasti</e1> .\n",
      "<e1>Spodmoli</e1> so <e1>vdolbine v navpičnih stenah pod previsi</e1> , <e1>ki</e1> navadno <e1>ne dosegajo</e1> dimenzij <e1>jam</e1> , <e1>njihova</e1> širina pa je <e1>večja od globine</e1> .\n",
      "<e2>Dolci</e2> so v Sloveniji <e1>značilni za dolomitna površja</e1> , <e1>njihova morfogeneza</e1> pa <e1>je vezana na delovanje fluviokraških procesov</e1> .\n",
      "<e2>Dolci</e2> , tudi dolki , so <e1>plitve dolinaste reliefne oblike brez površinskega vodnega pretakanja</e1> .\n",
      "<e2>Dolec</e2> je značilna <e1>oblika dolomitnega površja</e1> .\n",
      "Dolek oziroma dolec je <e1>geomorfološka oblika</e1> , ki je zelo sorodna suhi <e1>dolini</e1> in se od nje razlikuje zgolj po velikosti .\n",
      "V kraški hidrologiji pomeni <e1>piezometrični</e1> nivo oziroma nivo <e1>podzemne vode v krasu</e1> navidezno višino vode <e1>v kanalih</e1> , ki <e1>vodijo proti</e1> izviru .\n",
      "<e1>Dejavnike</e1> , <e1>ki v sistemu dokončno podrejo ravnovesje</e1> imenujemo \" povod \" za nastanek <e1>zemeljskih plazov</e1> .\n",
      "<e2>Abrazija</e2> je <e1>destrukcijsko</e1> delo morskih in jezerskih <e1>valov</e1> .\n",
      "Erozija prsti je oznaka za <e1>proces</e1> , ki povečini prizadene <e1>prst</e1> .\n",
      "<e1>Premikanje preperine oziroma preperinski tok</e1> povzroči <e1>nagubanje sklenjene travne ruše</e1> , <e1>zaradi</e1> česar je <e1>na</e1> površju viden <e1>grbinast relief</e1> .\n",
      "<e2>Bruhalniki</e2> so <e1>kraški izviri</e1> , ki <e1>obdobno bruhajo vodo na površje</e1> .\n",
      "<e2>Korozija</e2> je <e1>posledica večje količine vode v nižjih legah</e1> .\n",
      "<e2>Erozijski jarki</e2> so stalna <e1>reliefna oblika</e1> , <e1>pogosta na strmih pobočjih</e1> .\n",
      "<e2>Mikrožlebiči</e2> so <e1>vzporedne</e1> , <e1>ravno potekajoče podolgovate vdolbine</e1> , ki se <e1>pojavljajo na bolj nagnjeni goli skalni površini</e1> .\n",
      "<e2>Korozijske stopničke</e2> so <e1>polkrožne kraške reliefne oblike</e1> , <e1>ki</e1> se <e1>pojavljajo predvsem na golem skalnem površju</e1> .\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FvjF1M0u4C2s",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_sentence = \"\"\"\n",
    "An aquifer is defined as a body of rock or unconsolidated sediment that has sufficient permeability to allow water to flow through it.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WG5qHlOJ4C2t",
    "outputId": "846b2bb9-c7a4-4349-ef3d-5be0ec66dafc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asd\n"
     ]
    }
   ],
   "source": [
    "tokenized_sentence = tokenizer.encode(test_sentence)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"asd\")\n",
    "    input_ids = torch.tensor([tokenized_sentence]).to('cuda')\n",
    "else:\n",
    "    input_ids = torch.tensor([tokenized_sentence])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gdzvU4P74C2t",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([tokenized_sentence])\n",
    "output = model(input_ids)\n",
    "label_indices = np.argmax(output[0].to('cpu').detach().numpy(), axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tkpeWwzU4C2t",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Join BPE split tokens\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
    "new_tokens, new_labels = [], []\n",
    "for token, label_idx in zip(tokens, label_indices[0]):\n",
    "    if token.startswith(\"##\"):\n",
    "        new_tokens[-1] = new_tokens[-1] + token[2:]\n",
    "    else:\n",
    "        new_labels.append(code2label[label_idx])\n",
    "        new_tokens.append(token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G-yqibETUhvr",
    "outputId": "b6345949-f9ed-464e-8654-55b929407c8f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'An',\n",
       " 'aquifer',\n",
       " 'is',\n",
       " 'defined',\n",
       " 'as',\n",
       " 'a',\n",
       " 'body',\n",
       " 'of',\n",
       " 'rock',\n",
       " 'or',\n",
       " 'unconsolidated',\n",
       " 'sediment',\n",
       " 'that',\n",
       " 'has',\n",
       " 'sufficient',\n",
       " 'permeability',\n",
       " 'to',\n",
       " 'allow',\n",
       " 'water',\n",
       " 'to',\n",
       " 'flow',\n",
       " 'through',\n",
       " 'it',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QeSUPWJw4C2t",
    "outputId": "b88546a6-ad1e-41ae-8eb1-10fbd0c43b24",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAD\t[CLS]\n",
      "B-DEFINIENDUM\tAn\n",
      "I-DEFINIENDUM\taquifer\n",
      "O\tis\n",
      "O\tdefined\n",
      "O\tas\n",
      "O\ta\n",
      "B-GENUS\tbody\n",
      "B-COMPOSITION_MEDIUM\tof\n",
      "I-COMPOSITION_MEDIUM\trock\n",
      "O\tor\n",
      "I-COMPOSITION_MEDIUM\tunconsolidated\n",
      "I-GENUS\tsediment\n",
      "O\tthat\n",
      "O\thas\n",
      "O\tsufficient\n",
      "O\tpermeability\n",
      "O\tto\n",
      "I-HAS_FUNCTION\tallow\n",
      "I-HAS_FUNCTION\twater\n",
      "O\tto\n",
      "I-HAS_FUNCTION\tflow\n",
      "I-HAS_FUNCTION\tthrough\n",
      "I-HAS_CAUSE\tit\n",
      "O\t.\n",
      "O\t[SEP]\n"
     ]
    }
   ],
   "source": [
    "for token, label in zip(new_tokens, new_labels):\n",
    "    print(\"{}\\t{}\".format(label, token))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0630gx-44C2t",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The expected output should recognize entities (by the algorithm):\n",
    "\n",
    "* (PER) Dr. Marko Robnik-Šikonja\n",
    "* (ORG) NLP\n",
    "* (ORG) University of Ljubljana\n",
    "* (GEO) Slovenia\n",
    "* (PER) Dr. Žitnik\n",
    "* (TIM) Tuesday\n",
    "* (TIM) Wednesday and Thursday\n",
    "* (ORG) Televizija Slovenija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpuuwJlb4C2t",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Coreference resolution\n",
    "\n",
    "Coreference resolution can be approached in ways to exploit mention pairs for classification. We have already seen the [huggingface' example](https://huggingface.co/coref/) which is [open-sourced](https://github.com/huggingface/neuralcoref). Their model architecture looks as follows and training is described in [their medium post](https://medium.com/huggingface/how-to-train-a-neural-coreference-model-neuralcoref-2-7bb30c1abdfe):\n",
    "\n",
    "<img src=\"huggingface-coref.png\" width=\"60%\" />\n",
    "\n",
    "Another simple approach would be a combination of BERT embeddings of mention pairs and additional features combined using dense layers:\n",
    "\n",
    "<img src=\"bert-pair-coref.png\" width=\"60%\" />\n",
    "\n",
    "The model is described along with two additional baselines in the report [BERT for Coreference Resolution by Arthi Sureb](bert-pair-coref.pdf) (Stanford's NLP/AI class). \n",
    "\n",
    "## Relationship extraction\n",
    "\n",
    "There exist no (general) relationship extraction corpus for Slovene. We conducted an analysis with (semi-)automatic corpus creation and model training (see [https://github.com/RSDO-DS3/SloREL](https://github.com/RSDO-DS3/SloREL)) - Miha Štravs (MSc. thesis, 2022, to appear). The model and training is based on [R-BERT](https://github.com/monologg/R-BERT), unofficial implementation of [Enriching Pre-trained Language Model with Entity Information for Relation Classification](https://arxiv.org/abs/1905.08284).\n",
    "\n",
    "The architecture of a models looks as follows:\n",
    "\n",
    "<img src=\"r-bert.png\" width=\"60%\" />\n",
    "\n",
    "## Aspect-based sentiment analysis\n",
    "\n",
    "This task is quite novel and therefore I propose to try some architectures of your own. \n",
    "\n",
    "Still you are free to transform the task to sequence classification. For example, you can represent a sequence of a persion based on sequence of mentions with additional word neighbourhoods.\n",
    "\n",
    "There exist some BERT-based approaches ([an example](ABSA.pdf)) that deal with aspect-based sentiment analysis. Still, their task is a bit different and is based on SemEval 2015 and SemEval 2016 tasks. Those task are investigating different sentiment aspects for a given entity type in a review text. \n",
    "\n",
    "## References\n",
    "\n",
    "* [Transformers NER examples](https://github.com/huggingface/transformers/tree/master/examples/ner)\n",
    "* [NER example in Tensorflow](https://androidkt.com/name-entity-recognition-with-bert-in-tensorflow/)\n",
    "* [DeepPavlov models](http://docs.deeppavlov.ai/en/master/features/models/ner.html)\n",
    "\n",
    "## Other interesting examples\n",
    "\n",
    "* [Data Science workshop by Andrej Miščič and Luka Vranješ](https://github.com/andrejmiscic/NLP-workshop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9R9AM0wO4C2u",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "XpuuwJlb4C2t"
   ],
   "name": "Neural_sequence_tagging_PyTorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:nlp-course-fri]",
   "language": "python",
   "name": "conda-env-nlp-course-fri-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "aaf97f427e26474187d4b53810ff3a45": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3c13b89f527840fcbf579fa4e73b90ee",
       "IPY_MODEL_be030ac51b3b4607837e814744547fce",
       "IPY_MODEL_4951416c946a4a9eb29afb39a5c6bd04"
      ],
      "layout": "IPY_MODEL_898b30bf2d0d4a1bbeb08ef5551a5a55"
     }
    },
    "3c13b89f527840fcbf579fa4e73b90ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52b63a5b15a04c69ba62e04e20ec0c96",
      "placeholder": "​",
      "style": "IPY_MODEL_796349ba4ecd405ea86da703921c8aae",
      "value": "Downloading: 100%"
     }
    },
    "be030ac51b3b4607837e814744547fce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_373202bd2d6d4f17b1d3f9e10948e543",
      "max": 329130,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_553caad2335f49a38f6fa4926b8903cc",
      "value": 329130
     }
    },
    "4951416c946a4a9eb29afb39a5c6bd04": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e84d2bfd7ef40c19a4119873529ee98",
      "placeholder": "​",
      "style": "IPY_MODEL_df0270c256e440c0813eb4b00faffb5d",
      "value": " 321k/321k [00:00&lt;00:00, 653kB/s]"
     }
    },
    "898b30bf2d0d4a1bbeb08ef5551a5a55": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52b63a5b15a04c69ba62e04e20ec0c96": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "796349ba4ecd405ea86da703921c8aae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "373202bd2d6d4f17b1d3f9e10948e543": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "553caad2335f49a38f6fa4926b8903cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2e84d2bfd7ef40c19a4119873529ee98": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df0270c256e440c0813eb4b00faffb5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b03064e8ada549569d4fb615d0c0a474": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7b089464b67c4020a1c06506e010fcda",
       "IPY_MODEL_4e9af5e9147241dd9f0930d6d2d02618",
       "IPY_MODEL_62388b93157b44259c41ae4cbeadd2c2"
      ],
      "layout": "IPY_MODEL_a5d94bbad5534a04af9e0a13f261519d"
     }
    },
    "7b089464b67c4020a1c06506e010fcda": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e1d57272866498281f109fb0cdd9b9c",
      "placeholder": "​",
      "style": "IPY_MODEL_c3b1e27e478c4f34bd3a7bacbf0687e8",
      "value": "Downloading: 100%"
     }
    },
    "4e9af5e9147241dd9f0930d6d2d02618": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5bb8d135ac7c4c99aaf2fa746035a86a",
      "max": 46,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b39e823fa53d43cd8be0f32a4aba85cd",
      "value": 46
     }
    },
    "62388b93157b44259c41ae4cbeadd2c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f66a1404f4604834af6ff39eccfdf0d7",
      "placeholder": "​",
      "style": "IPY_MODEL_bdc2fbb2aaf7489297d35631a0635b39",
      "value": " 46.0/46.0 [00:00&lt;00:00, 405B/s]"
     }
    },
    "a5d94bbad5534a04af9e0a13f261519d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e1d57272866498281f109fb0cdd9b9c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3b1e27e478c4f34bd3a7bacbf0687e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5bb8d135ac7c4c99aaf2fa746035a86a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b39e823fa53d43cd8be0f32a4aba85cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f66a1404f4604834af6ff39eccfdf0d7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdc2fbb2aaf7489297d35631a0635b39": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cc5267d75c794e4ba1b1e34d931ca0d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4542410b022a477a8890b16ff10ad948",
       "IPY_MODEL_dd327fdbab954d9d872a1b4040b09471",
       "IPY_MODEL_81800401bf204d38bea4fa4ccce8e359"
      ],
      "layout": "IPY_MODEL_36370355038c4798b90180316f6ff890"
     }
    },
    "4542410b022a477a8890b16ff10ad948": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fdfd041b59bc44468325ef8914288d59",
      "placeholder": "​",
      "style": "IPY_MODEL_0a79601e24284345b128219e176e9815",
      "value": "Downloading: 100%"
     }
    },
    "dd327fdbab954d9d872a1b4040b09471": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b1d45d69f8e4c9db1c8e87ee53f90a0",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4a2f878c782f4395abfb081857c247ad",
      "value": 433
     }
    },
    "81800401bf204d38bea4fa4ccce8e359": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d282d17afbc4adc8937abd338793690",
      "placeholder": "​",
      "style": "IPY_MODEL_479b5d0a41134e9483e1a01fecc5f081",
      "value": " 433/433 [00:00&lt;00:00, 5.36kB/s]"
     }
    },
    "36370355038c4798b90180316f6ff890": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fdfd041b59bc44468325ef8914288d59": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a79601e24284345b128219e176e9815": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b1d45d69f8e4c9db1c8e87ee53f90a0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a2f878c782f4395abfb081857c247ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1d282d17afbc4adc8937abd338793690": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "479b5d0a41134e9483e1a01fecc5f081": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "45fe6b92b71e49abba45fc9e483aefdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_967a5f2400ba459eab80fe438ab6583e",
       "IPY_MODEL_7850bf86bd634637bbb44ec2bc3b9741",
       "IPY_MODEL_cc60d68eb8744ff19a7d97c8cdb220f1"
      ],
      "layout": "IPY_MODEL_cf2a8ff702fe467ba7a4a51429981905"
     }
    },
    "967a5f2400ba459eab80fe438ab6583e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3217ed8bd00a4e0f9dce9434692748a5",
      "placeholder": "​",
      "style": "IPY_MODEL_f07cdc882ce34524b8932b0cfad7fb03",
      "value": "Downloading: 100%"
     }
    },
    "7850bf86bd634637bbb44ec2bc3b9741": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97dd9aca649045378045ce48ad48f78a",
      "max": 499161406,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b7526b7addf64348aa0f27a98d4e1940",
      "value": 499161406
     }
    },
    "cc60d68eb8744ff19a7d97c8cdb220f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a711a4ec7e9b44dca62d852be6390cbb",
      "placeholder": "​",
      "style": "IPY_MODEL_0b86243a44144eab838db4eac13b6800",
      "value": " 476M/476M [00:31&lt;00:00, 17.7MB/s]"
     }
    },
    "cf2a8ff702fe467ba7a4a51429981905": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3217ed8bd00a4e0f9dce9434692748a5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f07cdc882ce34524b8932b0cfad7fb03": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "97dd9aca649045378045ce48ad48f78a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7526b7addf64348aa0f27a98d4e1940": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a711a4ec7e9b44dca62d852be6390cbb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b86243a44144eab838db4eac13b6800": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}